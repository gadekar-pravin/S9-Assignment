Nov 8, 2025EAG V2 SessionSummaryThe Admin introduced the critical role of heuristics, defined as "guard rails," in agentic solutions, noting that they are necessary to manage user errors and limitations of LLMs, which, while flexible, can hallucinate and overthink simple things, a point confirmed by Alpesh Mehta's understanding of heuristics as guardrails. The discussion covered various examples of heuristics, such as validating math equations and detecting sensitive data, and progressed to strategy profiles—Conservative, Exploratory, and Fallback—which define an agent's behavior and recovery from failure. The Admin detailed the code-writing agent architecture, explaining that it executes Python code in a sandbox with restricted functions to improve planning and execution flow, while Satish Jasthi inquired about code reusability, Rajit Badgandi asked about memory integration, and Sachin Bharadwaj and Pratesh Kumar Reddy R sought clarification on "code agents" and sandbox security, respectively, a point about modularity further explored by Amlan Routray. The participants were assigned to describe the architecture, fix a framework bug, write ten heuristics, index past conversations, and reduce the word count of a prompt file.Details? Introduction to Heuristics and Agent Capabilities The Admin introduced the session, noting that AI is only about 5% of the work, and the remaining 95% still requires human effort, with a significant part focusing on heuristics. They highlighted the limitations of LLMs and agents alone, especially when dealing with user errors, unexpected data formats, missing login access, tool failures, and constraints on the number of steps to complete a job, emphasizing that these issues require the addition of heuristics (00:00:57). The Admin defined heuristics as "guard rails" that ensure boundaries are well-defined for the agent, providing it with the correct tools and outputs (00:01:48).? Heuristics vs. LLM Reasoning The discussion moved to comparing heuristics and LLM reasoning, emphasizing that both systems work toward the same objective (00:01:48). The Admin stated that every data transfer among application steps, such as tool output or query results, needs a decision on whether the agent or heuristics should validate the correctness of the data flow. They acknowledged that working on heuristics is often viewed as "boring" and "old-fashioned," similar to unit testing, but stressed its critical role in separating successful agentic solutions from those that fail (00:02:48).? LLM Strengths and Weaknesses The Admin characterized the LLM as a "creative genius" that is flexible, smart, typo-tolerant, and context-aware, capable of handling bad or unbalanced data. However, the weaknesses of LLMs include the tendency to hallucinate, a lack of understanding regarding date differentiation (e.g., "3rd March or 4th of April"), or inability to detect if a wrong file or an image instead of text has been sent (00:03:57). They also noted that LLMs can "overthink simple things" (00:04:48).? Heuristics Characteristics and Collaboration Heuristics were described as "no nonsense engineers" that are fast, strict, and guided by pre-determined rules. They are unable to adapt to "fuzzy input," underscoring the need for both heuristics and LLMs to work in sync as a team, with each complementing the other's strengths (00:04:48). The Admin provided real-world scenarios illustrating when one system is superior to the other, such as using heuristics for rule-based tasks like email validation and unsafe shell commands, and LLMs for creative or context-sensitive tasks like interpreting "yeah" or "read my last email" (00:05:36).? Examples of Heuristics Applications The Admin provided examples of heuristics, mentioning that they are suitable for tasks that approach the boundary of cognition or are completely rule-based (00:07:36). The team suggested specific heuristics, including catching slangs or NSFW words in prompts, validating math equations, checking for incorrect input formats, detecting file size overruns, and screening for sensitive data such as company confidential information, passwords, authorization tokens, or account details (00:09:06). Further suggestions included identifying PHI (Protected Health Information) or PIA (Personally Identifiable Information) data, filtering out scripts that could run on the server, excluding unnecessary log files, and blacklisting unsafe or sensitive websites (00:10:56).? Advanced Heuristics and Practical Implementation The team also discussed heuristics for complex scenarios, such as preventing automatic billing/checkout (00:12:32), validating the formation of a DB query, and workflow validation from the agent (00:13:52). The Admin provided simple but crucial heuristics, including checking if a file exists on a path share, preventing excessively long inputs, detecting corrupted or invalid JSON files, and avoiding racial or black words in the output (00:14:59). Other critical heuristics mentioned were preventing prompt injection, blocking object code or non-ASCII characters, mitigating DoS-like service attacks, restricting calls to unlisted tools, enforcing timeouts, and limiting input file size (00:16:07). The Admin explained that participants are assigned to write their heuristics as simple functions within their module, which must become a permanent part of their agent solution (00:17:05).? Heuristics as Guardrails Alpesh Mehta confirmed the understanding that heuristics function as guardrails for the agent program, a point reinforced by The Admin (00:18:54). The Admin stressed that heuristics should be used every time data is transferred, from user input to LLM response and back, confirming that they are fast and do not pose a speed concern (00:17:57).? Introduction to Strategy Profiles The Admin introduced the concept of a strategy profile, which defines the behavior of an agent and determines how it responds to different situations (00:19:57). This strategy is incorporated into the prompt, giving the agent a specific personality, and helps guide it on whether to stop or move on when stuck (00:20:50). Strategies include conservative (e.g., transferring money, cross-checking everything) and exploratory (e.g., quick results like finding restaurants) (00:19:57).? Key Principles of Agent Strategy The Admin outlined crucial questions for determining an agent's strategy: whether it should "play safe" (extremely safe, conservative) or "try everything before giving up" (exploratory, persevering) (00:21:38). They also discussed how an agent recovers from failure, using the example of negotiating a bribe, and clarified the need to differentiate between the agent's strategy (e.g., bargaining) and heuristics (e.g., validating data) (00:23:34).? Plan vs. Policy and Strategy Types The Admin emphasized that agents should operate based on a "policy" rather than a "plan," as a policy can modify itself based on changing inputs, analogous to adapting to real-world complexities like road closures (00:25:47). The strategies should include conscious choices, such as whether to try a different tool upon failure, give up, communicate back, or check memory before searching again (00:26:59). Three primary strategies were identified: Conservative, Exploratory, and Fallback (00:27:48) (00:38:33).? Conservative Strategy and Grounding The Conservative strategy, vital for high-risk workflows like medical or engineering domains, ensures the agent will not guess if it doesn't know what to do (00:28:32). This strategy forces the agent to calculate and ensure the data is "grounded" before responding (00:29:13). Satish Jasthi inquired about ensuring certainty, and The Admin clarified that grounding means linking the answer to a "scientific return published fact" (00:30:06). The Admin also confirmed that setting the temperature to extreme and demanding citation (e.g., "page four paragraph 5") enforces the most conservative approach (00:31:02).? Exploratory and Fallback Strategies The Exploratory strategy allows for creativity, running multiple strategies in parallel, and comparing results from various sources. This is ideal for research agents operating in information-rich domains with ambiguity, such as finding the best time to visit a location (00:35:04) (00:37:24). The Admin defined the Fallback strategy as necessary for addressing failures by trying something else, noting that it is often integrated into the conservative and exploratory strategies (00:38:33). The Max Lifeline, set at three attempts in the current system, helps define how many times the agent will attempt a new approach upon failure (00:39:46).? Implementation of Strategies in Code The Admin demonstrated how different strategies are implemented in the code's configuration file, `profiles.json`, where the planning strategy can be changed between conservative and exploratory (parallel or sequential) (00:45:15). Key parameters like `max_steps` (for parallel/sequential steps) and `max_lifeline` (overall run attempts) define the boundaries of the strategy. The Admin also noted that LLM chaining with Python plans, including function piping, allows the agent to execute a chain of actions in a single step, improving efficiency and grounding (00:46:16).? Code-Writing Agent The Admin revealed that the current decision agent is now designed to write code to solve problems. This code is generated as a Python function, `solve`, with strict rules regarding function calls and formatting (00:41:57). The prompt for the conservative strategy was noted to be lengthy (6,483 characters), illustrating a style that needs optimization (00:43:54). The goal of the code agent is to propose a plan that explicitly uses chained function calls with error checking within a single step (00:50:14). The Admin cited Hugging Trace's research to support the idea that coding agents are often better, faster, and require fewer tokens for quantitative analysis problems (00:51:00).? Limitations and Application of Code Agents While code agents are powerful, The Admin cautioned that they cannot do everything, such as pure summarization, and are not good enough alone (00:53:09). The current decision agent is engineered to respond only in code, which is then executed in a sandbox (00:57:14). The Admin explained that code agents will be helpful for writing Python code for scientific and quantitative analysis, and also for writing HTML code for formatting reports and creating tables or graphs (00:55:06).? Agent Architecture and Execution Flow The Admin detailed the agent's execution process, which involves receiving a complex input and outputting a plan as Python code. This code runs inside a sandbox, where the valid tools and schema are checked, and a log call is injected for introspection. The code is designed to include a `solve` function with validation logic if multiple tools are involved (00:58:18).? Sandbox and Code Validation The sandbox environment is restricted to an allowed list of functions, libraries, and modules. Specifically, the process ensures the tool is in the current registry, arguments are validated using Pydantic, and a timeout (20 or 10 seconds) is enforced for execution (00:59:07). The Admin also mentioned a limit of three function calls per script (01:00:03).? Benefits of Python Planning over Traditional LM Flow The Admin explained the advantages of generating a Python plan, contrasting it with traditional LM flows where tools might fail without explanation. Python code prevents planning drift because the whole plan is part of the code, and it avoids unnecessary tool reuse by allowing for a plan cache (01:00:03). Additionally, Python allows for testing output validation, which prevents over-trusting outputs as an agent might (01:01:09).? Code Reusability and Caching Satish Jasthi inquired whether smaller chunks of the generated code could be cached and reused across different problems, particularly for subparts. The Admin confirmed that reusability depends on how the code is written (01:02:06).? Real-World Use Cases and Prompting Real-world examples were presented, such as extracting and captioning images from a PDF, or searching F1 standings to update a Google sheet and send an email (01:02:06). The agent communicates its plan to the sandbox using Python as a language. The recommended prompt structure for the LLM planning phase instructs them to write a complete Python function using `call_tool_name` with validation logic and conditional checks (01:03:09).? Decision Agent Process and Forcing Tool Use The process involves perception output and the query going to the decision agent, which is instructed to only write code or give a final result. The Admin shared that they had to force the agent to use the correct tool by prompting it to write "boxing" to ensure it understood how to call the tool correctly (01:04:40) (01:06:46).? Memory Integration Rajit Badgandi asked about employing memory in the flow, to which The Admin responded that memory would be integrated as a function that can query memory or a part of RAG (Retrieval-Augmented Generation). They clarified that this is achieved by providing a tool catalog to the LLM (01:08:06).? Limitations of Code-Only Solution The Admin addressed a potential misunderstanding regarding the benefits of the new approach, confirming that avoiding multiple LLM calls is not the only benefit (01:08:06). They explained that enforcing code generation now is a strategy to experience the challenges of working solely with code, emphasizing that it's not the only way to solve problems and that the next step will allow the agent to either write code or solve problems directly (01:09:13).? Current Agent Limitations and Adaptive Planning Currently, the agent is limited; it cannot import or execute new functions, meaning it can only use pre-defined functions. The Admin then introduced the concept of adaptive planning loops, which are necessary because agents can fail due to misinterpretation, misreasoning, or clinging to a wrong plan (01:09:48).? Common Reasons for Agent Failure The Admin provided an extensive list of reasons agents fail, including misinterpreting input, incomplete perception, poor confidence, insufficient memory recall, retrieving wrong information, wrong tool selection, tool misuse, and API failures (01:11:16). Failures also include drift based on invalid assumptions, poor plan generation, bad prioritization, and missing edge cases (01:12:35).? Addressing Agent Failures Two main ways to solve agent failures were identified: heuristics and having a solid fallback mechanism (01:13:39). The core of the adaptive planning loop involves planning a step, executing it, and retrying if a failure occurs, but within a controlled retry budget (starting with three attempts) (01:15:39).? Architectural Diversity Based on Problem Type The Admin stressed the importance of flexible architecture by contrasting two stock market agents: one for long-term investments and another for options trading (01:16:58). They concluded that the architecture must change based on the specific problem, with the goal being to create a generic architecture that can be fine-tuned for particular use cases (01:20:09) (01:43:01).? Adaptive Planning Strategies and Tool Switching Adaptive planning involves intelligent and sequential fallback mechanisms when the primary path fails (01:15:39). Tool switching can happen via hint-based alternatives, memory awareness, or by writing a sandbox script to check options. The Admin highlighted that memory needs to be contextual, not just simple chat history, to enable effective hint-based switching (01:21:01) (01:23:19).? Evolution of Agent Intelligence True intelligence for agents involves remembering, adapting, and evolving tool and function calls, moving agents from stateless to stateful architecture (01:26:00). Storing a log of intent, entities, tool used, and success status after each execution is crucial for this stateful architecture (01:27:52).? Memory and Tool Prioritization Memory teaches the agent to avoid past mistakes, offer guidance, or copy successful tool chains (01:26:54). A lookup planning table prioritizes tools that have been recently successful, using statistics to avoid calling frequently failing tools (01:28:43).? Assignment Details: Architecture and Bug Fixing The current assignment requires the participants to describe the architecture of the provided code in full detail, preferably hand-drawn, focusing on the flow of information between files and modules (01:32:54) (01:40:20). The assignment also includes fixing a bug in the framework that limits running certain queries, writing ten heuristics, indexing past historical conversations, and significantly reducing the word count of a prompt file (01:35:34).? Generic Architecture Goal Satish Jasthi asked if a structured flow visualization, similar to app design using Figma, is useful for developing agent architectures, and The Admin confirmed that this approach is valuable for solving specific problems. The ultimate goal is to develop a generic architecture that can solve 90% of problems and be modified for specific use cases, such as stock trading (01:43:01).? Definition of "Code Agent" Sachin Bharadwaj inquired about what constitutes a "code agent" versus an LLM call (01:43:57). The Admin clarified that a code agent relies on the Python sandbox and does not call the LLM directly; however, calling an LLM through an MCP tool while operating within the sandbox blurs this line (01:44:54). A true code agent solves the problem using equivalent code without leaving the Python environment (01:45:38).? Sandbox Security and Guardrails Pratesh Kumar Reddy R asked about the Python sandbox creation and if it handles unsafe commands like `rm -rf` (01:45:38). The Admin confirmed the existing sandbox already prevents shell commands (01:47:01). They suggested that creating a guarded `run_command` function that uses `subprocess.Popen` is a correct approach, provided that strong guardrails, potentially including a validating LLM, are in place to check for unsafe commands (01:53:25).? Separation of Concerns in Architecture Amlan Routray questioned the necessity of having separate files for `loop.py` and `context.py` (01:49:44). The Admin explained that this separation is driven by modularity and separation of concerns, ensuring that specific logic, like heuristics related to the loop, is contained within the relevant file (01:50:54).Suggested next steps The group will update their code base to include multi-tool dispatch to run multiple tools for exploratory strategy in session 11 or 12. The group will write their heuristics as a set of tools in their own module, keep them, and make an extremely dense huristic file for themselves that should be part of their plan always. The Admin will fix the prompt that is being made very very long.You should review Gemini's notes to make sure they're accurate. Get tips and learn how Gemini takes notesPlease provide feedback about using Gemini to take notes in a short survey.?? TranscriptNov 8, 2025EAG V2 Session - Transcript00:00:00 The Admin: bit of coding process that you will have to go through sort of things that you like to avoid but unfortunately you still have to do because um I said this multiple times in my own company also that uh AI is literally 5% of everything else 95% of the work still has to be done by us and a big part of that is going to be what we will discuss today and there's a major upgrade on the overall software that you're also writing uh we're going to discuss a bit of that but essentially we're going to start with the huristics part and why that is important and why some of the stuff that u we may just assume that is not required is actually done by openi and other people as well it's pretty solid pretty detailed and um lot of planning and work goes inside that so till now our agent has been literally uh doing everything we just throw a prompt on the agent and we expect the agent is going to be coming back and telling us that this is the answer to our queries.  00:00:57 The Admin: It perceived it planned, it acted everything was done by the agent or the LM behind that. But the problem is what if the user says show my calendar I made a spelling mistake there. Uh our LM can understand the spelling mistake and fix it. But the problem is let's say there was no login access provided or some some for some reason it was lost. when a date comes as 030425 we are expecting that uh I expected it was actually March 4th and not 3rd of April right then there's a confusion then let's say a particular tool failed and we never learned that a tool failed also and that can happen in a lot of lot of times especially the way we will be writing our uh receiver for the program output and what if there were five option to do something but we've only provided three steps that you have to finish the job in three steps so all of these cases are beyond what agent can do beyond what LM can do and That's where we have to add a bit of heristics.  00:01:48 The Admin: And the way to think about heristics is you have to think of them like guard rails. They are there to essentially make sure that boundaries are very well defined for the agent and the agent can work inside them and it's provided with the right set of tools and outputs as well. So initial part of the session we're going to discuss heristics versus LM reasoning and uh who should you trust like what part of the role you're going to pass on to LM what part of the role you are going to decide to keep it with the heristics part. So these are two systems but the mission is same to achieve the final objective we have a problem to solve and for that we need to use heristics and LLM and when we're talking about herostics here or this decision we decision we're talking about every single data transfer that happens amongst our application it can be the tool output it can be the search result uh it can be the query result that we get from internet it can be the MD output markdown output it can be our own classification of uh what file is supposed to be like probably we assume that a file is a small file but it's actually not.  00:02:48 The Admin: So all of those things that we assume or all of those things where the data is actually transferred from one step to other step we have to take a call it is the uh agent's job or it is heristics which need to come in and classify that this step is correct or data being flowing data flowing is correct. Heristics are something that you'll hate to work on because you'll have to think or you don't like to think especially on Saturday but you'll have to think about it especially when you make when you make your application it is boring because I can literally make it make you hate it if I tell you this is like unit test right and very very important is oldfashioned because it essentially goes back to the roots where every single step has to be checked and you think that okay I'm confident it's going to work but there are going to be cases where it's going to fail and this is something that is going to force to think much more deeper much in now much more deeply deep deeper fashion for what is it that you want to build now but believe me this is one of the most important factors that are currently separating the uh people who can deploy agentric solutions versus people who don't uh there's a very famous MIT study where it was misinterpreted as saying that 95% agent fail that's not what they said they said 95% companies do not know how to uh execute  00:03:57 The Admin: agents properly and all of them actually fall in this particular category where heristics are not involved in a way where we make the life of someone like LM easy. So to compare heristics with LLM, these are the things in which you have to think about let's think of what LLM can do. LM is a creative genius. You can do spelling mistake. You can ask you to create something. You can throw in sort of a balanced data or bad data and it will still be able to figure out its strength is that it's flexible, right? It's smart. It's typo tolerant. It's context aware. All those features are there. The weakness is it can hallucinate. It has no idea whether uh you said 3rd March or 4th of April, right? Third March, 3rd of 4th of March or 3rd of April. It has no idea to differentiate amongst that. It has no idea that uh you've sent a file and you ask it to summarize but for some reason you have sent the wrong file.  00:04:48 The Admin: It has no idea that the file that you have sent in PDF has a image instead of text. It has none of those ideas and it's just going to look at image. It's going to see oh I couldn't find anything and responds back respond back based on that. Right? and it will overthink simple things that is super easy for us to solve. Heristics on the other hand are no nonsense engineers. They are fast and strict at the size. They're guided by rules and the rules have to be determined by us. They cannot adapt to fuzzy input which we may tend to provide. Right? So if you think deeply you're going to see that both of them have to work in sync. They are a team. One of them is uh someone who is playing T20, the other one is playing uh test but both of them have to play together to make sure that one day can be win can be won together. Now the new rule of thumb for your agentic solution is going to be something like this.  00:05:36 The Admin: These are some problems and after I share these uh problems I'm going to ask you of some of the heristics that you can come up with. Now look at the real world scenarios here. Email validation. It is nonsensical to use uh something like an LLM to identify whether the email is correct or not. Can it do it? Of course, it can do it. But these are rules based and if we pass on this job to our LLM, then we are in trouble. They can fix it. If if anything still goes beyond our tests, LM can still go and fix that particular part. Data passing or date passing the fixed logic to that, right? We can interpret the information in wrong way. LM can also do it. That's why we have to enforce that into a system where all the data coming in has a specific date format when the user says yeah heristics has no idea what is what is the meaning of that but LM can understand that right in that case LM is going to win uh let's say is asking back would you like me to elaborate and you said yeah like LM will understand but if this was handled by heristics that we are expecting yes yes yes please do it then we're going to fail because humans in output or humans input output is always fuzzy show my calendar.  00:06:44 The Admin: Now here heristics are going to fail. There are mistakes that are there in spellings that heristics will not be able to rectify and proceed accordingly. But here LM can definitely understand. Now unsafe shell there's something that where heristics are just going to win wherever we have uh we're trying to R minus RF that we discussed earlier in heristics we can understand that it's not supposed to run you're importing a particular file which is not a particular module where you're not supposed to do it. LN can get hallucinate. LM can handle it and still call that particular library. But at heristics level, we can just stop it. Similarly, read my last email. Now, in this case, can we do it through heristics? Yes, read my last mail is very simple command, but there's no guarantee you're going to be doing saying the same thing again and again, right? You might change the words next time. So, heristics will need a tool hint. Do something like this. But in our case of LLM, it can deduce that your email essentially is Gmail.  00:07:36 The Admin: So, it knows that you're talking about opening a Gmail. If amount is more than uh 5,000 then flag. Now here we are going to write code with rules. In case of LM it needs few short prompts. So sort of equal when you have things that are um approaching the boundary of cognition and it's beyond the uh simple set of rules then we are looking at heruristics versus LLM battles coming into picture. When it's completely creative then it's completely LLM. It's completely rulebased. It's completely heristics where something in between then you will have to think about it who do we actually pass it on to. Now input is just URL. It's very simple for heristics to understand that the URL is correct and it can be proceeded with whereas it uh the LM actually can can get confused especially um now the modern LMS are getting better but imagine the LLM is reading the URL where the URL itself is your company.com/ this is a blog post about Andrea. HTML and inside the page we are reading something about EVs right so LM have now certainly got and kapati also in context and it will start thinking from that perspective now before I proceed further the exercise the common exercise that you and I have to do is now you should come up with your heristics ideas so tell me what you think give me heristics idea let me Start by saying that uh slangs or  00:09:06 The Admin: uh NSFW words in the prompt. If something something is like that I can write a heristics to catch it and recommend my user to rectify that ideas speak up.Rajit Badgandi: M questions.The Admin: What about that?Rajit Badgandi: Uh we can manage it with heristics. Validating a math equation.The Admin: Validating the math equation.Manoj Kumar: incorrect input formats.The Admin: Correct.Nawaz Ali: Regular expressions.The Admin: Uh that will fall into incorrect. I'm asking you to think like a little full different domain. For example, a 5GB PDF file mentioned that thing four uh we we'll call it uh personal data.Manoj Kumar: Yeah. Size overruns. Yeah.Arpan Das: Uh extracting data from passport will that be restrict? Okay.The Admin: What is it that you would not like to send to LM? What is it that you like to clean up or make sure it's not been passed on?Lakshmi Narasimhan Naveenam: Company confidential.The Admin: Correct. I'll say passwords and authorization tokens or keys. Uh let's add open, right?Vinay Ramachandran: account details something like that.  00:10:56 The Admin: uh goes here configuration parameter part of thisVinay Ramachandran: Okay.Arpan Das: Configuration parameters.Sunill Lalwani: It could be confidential information pertinent to to off uh say organization.The Admin: shift. That's fine.Sunill Lalwani: Yeah.The Admin: Anything else?Ritesh Verma: uh PHI or PIA data. I mean it can be in 6. Yeah.The Admin: Um, I'm assuming comes here and safe.Rishikesh Kumar: Any scripts or something from input which can run on server.The Admin: Good. more yield.Surya Ashish Dantla13: legal documents.The Admin: What about that? You may have asked it to evaluate your agreement.Surya Ashish Dantla13: Yeah.The Admin: So that won't be part of it.bhavya kamboj: Trademarks and copyrighted material.The Admin: What? No, it describe it. You're just saying one word. So it's without context for me. What about it?Manoj Kumar: some unnecessary log files shouldn't I mean optimize the token don't keep sending it again and again.The Admin: What about it? Okay. Uh do not job or data work or data flow something like that.  00:12:32 Manoj Kumar: Yeah. Yeah.The Admin: Good.Sunill Lalwani: Nar web details any website which shares from the darkThe Admin: Okay. Uh we'll call it unsafe or sensitive sens website and++ right browsing there or taking data from there you may not want that you may not want to uh site for example al-qa.com in your report when you are sending it to a client What?Priya Raja: Can it be uh like when you check out you know in online shopping? So the check out process where we need to enter our card details right like we would not allow the agentThe Admin: What about it? Okay, look. I just explained this that I will not like to involve any unsafe or sensitive website. Now, when you're saying that line, describe it well. What do you mean?Priya Raja: to do automatic checkout right from the cart.The Admin: Okay. Automatic billing or check out.Priya Raja: Yeah, correct.The Admin: Okay. Good.Sunill Lalwani: It could be malware.The Admin: Malware. I'll put it a part of this.  00:13:52 Sunill Lalwani: Okay.Rashi Agarwal: the formation of a DB query.The Admin: Uh, good one. It may may not be there, but it's it's something that needs to be done consciously.Rashi Agarwal: Yeah.Raghav SK: Um can it be used for like separating like on that checkout point? Uh there will be certain you know um pre- validated services that we use for checkout all those uh payout desks and all that. So that information should go securely to that desk without the LLM reading it. Can it be used for that kind of stuff?The Admin: Yes, but you have to define it again.Raghav SK: like when that step so when that step comes where you have to pass that information this workflow will do it and it'll not send it to the LLM and then the output of that pass or fail it'll send it to your agent maybe something for that kind of thing or hiding parts of the workflow uh you know which should not go to the agent is needed for that workflow, right?The Admin: Um, in one n can I say workflow validation?  00:14:59 Raghav SK: Uh from the agent. Yeah.The Admin: Okay, now all of you have started thinking extremely complex thing. Okay, let me write simple things here. Can we do a check that I mentioned already file doesn't exist on the part share okay too long input I'm sharing few things to open up your idea to how do we think about it or corrupted file howAlpesh Mehta: Yeah.Athvaith Krish: running command line. RM minus RF. This isThe Admin: many times this happens for us right corrupted file then we have something called invalid JSON you are going to be struggling with you're going to hate JSON very soon. You're going to say that if JSON was a person, I would have killed the person or for example, we've covered it, but something like in this format racial or black words that we do not want to process in the output or what about a prompt injection, we need to avoid for that also. Somehow maybe our prompting what the user is sending uh is getting he's installed a small Chrome plug-in which will add additional information in the prompt and send it.  00:16:07 The Admin: We don't want that. We do not want any object code. Do you know what is object code? Object code is that can be directly compiled on Python or C++. We do not want any non-ASKI characters. Everything that is asai we are okay. We want to make sure that there's no uh D2OS. For example, our agent is not creating a D2S service attack kind of code that keep on visiting now NC website like 20 times per second. We do not want to call any tool that is not in our tool that is not in our list. These are simple things that you have to think about. Most importantly, time out, right? You've called a function. We have called a service. You're looking for a website and we are just waiting for the result for more than 20 seconds. You need to come up with these this simple thing also input file limit. Right? You see that this in chat that you can only add 5 6 10 right?  00:17:05 The Admin: Are we clear? Yes or no?Alpesh Mehta: Yes.The Admin: Okay. Now the reason we discussed all of this is because a part of assignment for you is going to be write your heristics. These are the set of tools that you are going to write in your own module and you're going to keep them with yourself. You're going to make sure that this is a very simple function. All it has to do is to look at the text and figure out something, right? And uh this heristics module is now supposed to become uh part of your agent solution. So whenever you're writing any agent in your office for a personal work or anywhere else, you're going to make sure that this is true. Imagine that you made a Chrome plug-in that sizes website for some unfortunate reason there's a website that should not be visit visited on your browser and your child has clicked on it and your plug-in is going through it and explaining in much more detail. nonsense that can happen.  00:17:57 The Admin: So we need to make sure that you're keeping heristics as a part of your plan always. It's boring. You have to think of it once. You can ask charg to come up with more heristics that will make sense for your case. But do not forget these simple ones. They are very very important to be part of your overall scheme of things right. So if you want to validate intent, you're going to get the element who can win. But if you want to validate input, you're going to get the heristics involved. Always use heristics as a bouncer. make sure that uh hostix is a part of every single time a data is entered from the user to the LM LM's response going on a website coming back from and it is fast it will run in nanoseconds you do not have to worry about speed because here we're talking about set of rules that need to check very very fast right now computers are 3 GHz 8 core massive RAM and it will not create any problem at all right so some of the things that I mentioned in the text are also mentioned here to name not repository input looks suspicious timeout or retry up to three attempts and so on.  00:18:54 The Admin: Arish.Alpesh Mehta: Are this equal to the guardrails that we have around our program agentic programs?The Admin: Okay. And repeat that.Alpesh Mehta: Are are this uh equivalent to guardrails that we have for our agent program?The Admin: These are the guards that you have to build for your a program.Alpesh Mehta: Okay.The Admin: Okay. Any question on heristics? What are these and when do we need use them? We need them always. What are heristics? These are set of fruits that allow us to make sure our data is clean. Are we clear? Okay. So, you're sort of already doing this, but you need to make a extremely dense huristic file for yourself. That that should be something that is a part of your thought process from here on. Are we clear?Alpesh Mehta: Yes.The Admin: All right. Okay. Next part. Now we're going to talk about the strategy profile. Now strategy profile is something that is part of all the prompts.  00:19:57 The Admin: And uh uh when you're making these prompts, you need to make sure that you understand the strategy at which you want a prompt to work. We're going to discuss what this is. So it's sort of a behavior of how your agent needs to respond to a particular situation. And the situation is also going to determine what kind of strategy you're going to pick. For instance, you're trying to transfer money to someone. In that case, you need an extremely conservative agent which is going to cross check everything which is going to make sure that it is trying only once. Whatever failure it has, it is going to analyze that failure and then it's going to decide what to do next. Sometimes you're just looking at quick results. What should I eat or what are the restaurants in Bangalore? There you're not concerned that uh the first URL failed so I should understand why the URL failed. you're just going to check all and come back with the result. And in both the cases, the the third one I'm going to mention is a strategy, but I tend to include them in the first conservative and second exploratory strategy also.  00:20:50 The Admin: It's called fall back. Fall back is if something happens, what should I do next? Right? So fallback strategy itself is a strategy. You try something, it fails. You try something, it fails. You try something, it fails. And keep on trying it till it actually works. But you have to mix the fallback strategy to your uh uh aggressive strategy also and in the conservative strategy as well. So what are we saying? We're saying along with the tools and intelligence when you're going to be writing a prompt, you have to specifically mention these words to give your agent some sort of personality. And it's sort of a guide that is going to tell how to solve a particular problem that if you're stuck then you're supposed to stop or if you're stuck then you're supposed to move on. For example, you're writing a agent to turn on the nuclear reactor. It tried once and it stopped. What should you do? Should you ask ask it to try again or keep pressing that button?  00:21:38 The Admin: right? may not be the right strategy but uh uh you're trying to find the price of a particular product on website and for some reason Amazon failed you may want to check it on other website maybe go directly on a flip card website or maybe some other website that is also selling on Danzo used to be there now we have a blinket and other things also maybe you can check the pricing there right so questions that are going to determine on what uh principles your agent is going to be working on are linked to these questions does it play safe. Does your application require a safe agent? Safe like when we're saying safe, it's extremely safe. This is a person who um like is extremely safe like take bath three times a day, brushes three times a day, eat thighs on time, drinks water, carries his own water. That kind of agent like completely u doesn't even touch he's always carrying your um the coin I forgot forgetting his name. Right. So is that kind of agent?  00:22:34 The Admin: Yeah. Right. Or does it try everything before giving up? Here we're talking about um maybe for example your BI hero, right? Everything I I don't if you want to waste four three hours of your time, watch BI4 was running on TV for some reason and I was just getting surprised. I was like how bad can one movie be? I think this is the best movie I've seen uh with a ranking of 2.34 last time I have. I I don't remember when is the last time I saw such a bad rating. Where is it right now? 2.4. Doing well. From 2.34, it has improved to 2.4. So, it's doing well now, right? So, um that kind of story or a hero who just doesn't give up, right? Continues like just like our a neo in matrix, right? And agent is our agent is getting surprised and getting angry. Why? Why don't you give up? Why don't you keep on fighting, right?  00:23:34 The Admin: that kind of agents continuously just fighting after fighting after fighting. And how does a agent recover from a failure? Right? Uh there are some agents uh for example you when you jump a red light, you say request the uh police guy that he's forgive me and he says no forgiving. So you give the money, right? So you recover from a failure by giving money. So you want your agent to do it. So those are things that we need to be aware of. Now these are strategies that must be clearly defined right for example maybe in future you write up agent to negotiate with government employees or for some government work and the employee from the other side is saying like give me 5,000 I'll do your work and agent is being extremely safe do whatever you want to do gone but agent says actually negotiates understands the Indian context 5,000 is slightly more I'm still earning I have five kids and three wives and six cars and 17 parents and we can talk like that and say can these ad are just something why don't you do in 500 rupees right so has to be done and there are things that will happen uh very soon in fact this pali you know right she just came up with a video she's her is always scary so I think it's pali Yeah.  00:24:53 Ritesh Verma: So uh so I'm sorry for interrupting. So an agent should be allowed to do this kind of bargain on on a human prompt or this this should be an uristic I mean this kind of stuff that you so just said no.The Admin: So I I'm mentioning it needs to again we are discussing uh two different things. One is heroistic where heristic needs to come in and uh decide what it is supposed to do, what is it not supposed to do and the data is correct or not.Ritesh Verma: Yeah.The Admin: And second is bargaining. That's the agent that you're making right.Ritesh Verma: Okay.The Admin: So it's a strategy part. Safe agent no bribe second agent without bribe nothing works in the country. So you need to decide what is your agent. Watch this video.Ritesh Verma: Got it.The Admin: Yeah, watch this video. It says that a million jobs lost in US because of AI and she's scaring everyone and with data and uh making that face that very dangerous. Okay. So now strategy is problem solving policy.  00:25:47 The Admin: You need to understand what's the difference between plan and a policy. A plan is that you and your partner have decided to go out at 3 p.m. And if the partner not ready by 3 p.m. You decide not to go, you change your clothes and sit on your sofa and get beaten up. All I say is you and your partner decided you have to go out for something at 3 p.m. You are already at 3 p.m. dot. Then you're waiting for 3:13, 3:15, 3:30, 3:45, 4 4:30, 4:45, 5. And by the time you're at 5, you're going out. Your mission is accomplished. and you still get beaten because of you the the person was late by two hours. So policy is something that can modify itself based on um input changing right. So you should never have a plan when you're making an agent. Please make sure that you have this and this is coming from reinforcement learning. a plan is that uh I have to go from my location to a location B and that's a path that's the best path and we have decided but that's not how the real world also is right maybe the fly is closed maybe new maybe the same Gandhi is coming in and now people have just gone to the big political blockade on the road so I have to take some back road maybe the road doesn't allow for  00:26:59 The Admin: my car so I have to take my scooter all those things have to come in that's policy the agent should have a policy not a plan right so you have to make a conscious understanding of these things so just like ment we can allow the agents to make choices should I try a different tool if there's only one tool to do something and it fails then what do you do should you stop at the production level can't assignment yes you can say that okay my tool didn't work and I'm not sub submitting the assignment but uh you can't say that to your client that my tool is not working I'm not going to submit this uh project to the client you can't do that right should I give up if I'm I'm sure should we communicate back should we take some more feedback these are policies that have to be added to your uh agent prompt right should try memory instead of searching again. Have I answered this question earlier? And once you start thinking of these lines, they are going to become essentially the part of your uh agent.  00:27:48 The Admin: Now we've already seen modeler agent uh getting into picture. You're going to be making extremely modeler. By the time you're going to finish the course, you'll have 10 different agents talking to each other and all of them will have a bit and pieces of what we're discussing because they are supposed to sit in different directions. There are going to be agents which are supposed to be like that guy who's always planned and there is no exception. It is asked to do a it does a fails and comes back and tells her I have failed right and that's going to be our coding agent for example. It tries a code fails and gives back information I have failed. Then we can ask it to write a second code. That's a different thing, right? It's not coming back that it wrote a code like how we gave our uh J or CAD exam, right? The question came in, we try to solve it, solve it, solve it, solve it. You saw the watch, you have spent more than five minutes, you answer it zero.  00:28:32 The Admin: We don't want a coding agent like that, right? You have given a problem and comes back and say answer is zero. Most of the time it is. But most of the time answer is either B or zero. You remember that if you take an MCQ, right? We don't want our agent to think like that. Okay. So first strategy, we've already discussed the strategies. But now look at it in a text format. So first is conservative strategy here. If I don't know what to do, I won't guess. Right? This is very important. And this is these are the agent that are going to be the medical domain engineing domain. When I say like making a building, how many pillars we should add? I can't calculate but I think let's add 14. Not a good agent, right? We want to make sure that uh it is uh well taken care of. U let's buy a house. Okay. What is the cost of the house?  00:29:13 The Admin: Uh 6 cr. What is EMI? I don't want to calculate maybe one lakh okay let's buy we don't want those kind of agents right so there are cases where you will want to have a conservative extremely conservative strategy where you want your agent to calculate to make sure it's the data is grounded and then it's uh sort of given back uh to us or to the client so the agent is going to plan for a single step step at at a time and if it's unsure it's going to or or a no good plan emerges it's going to come back with the answer that I don't No, it is very important that uh you understand this that don't like to do this. Alarms do not like to come back and say I don't know, right? And they're just like humans. I don't think they've read I don't know a lot of times in the data set. You ask it something. For example, what is the favorite color of sun god? It will come back with some answer.  00:30:06 The Admin: It's like if you ask people in Bangalore what is a brow to location? A answer is always dead and right. Right? So elements are like that all the answers are dead and right or I don't know. We don't want that to happen and you have to force the element using constructs to ground the answer. Moment it can't ground the answer it will come back and say I don't know or I have not been able to find the grounding of this particular u thing that we're discussing. Correct Satish?satish jasthi: Uh Rohan having said this this same thing even in conservative strategy how can we be sure that it will not I mean there is no certainty right even with aThe Admin: Grounding. The answer is grounding. The meaning of grounding is that there's a scientific return published fact somewhere where it is uh mentioned as true.satish jasthi: okay and okay oh yeah okay okay I think you defined itThe Admin: That is what that is what perplexity is. Okay. Open all that's that is creativity that is how creative or how how diverse you want the answer to be that is the LM response but even in that case even you have  00:31:02 Arpan Das: Uh Ron won't own temperature help us achieve it. Temperature setting it to zero the temperature of the in the queries.The Admin: temperature setting set to extreme you have to ask it to ground it you have to tell it that tell me where have you read it moment you do it then it's grounded That's the most conservative strategy.Arpan Das: f*** yeah.The Admin: I read in the document on page four paragraph 5. I read on the website and the website happens to be a good website like India india.gov.in not Reddit. Right. So that grounding also has to be confirmed. Nas they were not they are not implemented.Nawaz Ali: Rohan. So uh in session 8 right uh the code did have these uh different strategies um and okay because like I I I tried using the same code uh for my assignment and when I was running the find theThe Admin: I just mentioned today we're going to see a prompt for theseNawaz Ali: top uh F1 race champions right it used to give me unknown and then I used to rerun it and then I used to get the answer and at that time I didn't understand it But now when I think about it, it makes me feel that okay, was it a conservative strategy that was being picked up and that's why I was getting an unknown or was it hallucinating?  00:32:25 The Admin: I I don't think the code was using it. It just mentioned it. It was supposed to be expanded. Now, for example, the code I'm going to share today already has code for session 10. So, a bit of code for session 10. So, in the last code we have, I don't think it was implemented. It was just mentioned there as a block.Nawaz Ali: Okay. All right. uh and one follow-up question is I'm not able to understand when will it become a like let's say if we have an agent that's uh conservative uh and I'm clearly saying that okay get me the stock of Google um it's as simple as going into the browser and getting it right where why would it Okay.The Admin: getting from where is the question right getting it from nse getting it from rediff getting it from there's a screener.com getting from where is important or getting it from a news article. News article will give you tomorrow, yesterday or day before yesterday. So when you're asking for something, it has to ground it and ground it with facts that are relevant to your question at the time.  00:33:31 Nawaz Ali: Makes sense. All right. Thanks, bro.The Admin: Okay. So conservative strategy, you're going to come up with these kind of prompts if you're working in a high-risk workflow. For example, you're suggesting a medicine there you will not do a Google search and come back with that. Okay, someone said that take paracetamol for everything and that will work, right? We don't want to do that. Or for example, there's a this guy, I don't know, it's a it's a scam. Please do not fall for it. Uh he is getting extremely famous with this guy in uh uh Bangalore getting I can't tell you how many people are falling for it and I'm scared that if I show it to you then you will also fall for it. Don't do that. This guy takes a sketch pen camel sketch pen puts it on a finger and says the cancer is treated and he has a double PS in color therapy probably in his own college and he's providing certificate for others to become color therapy therapist 25,000 rupees a course I was thinking that I should stop that and actually do this uh uh take this course and actually do this course better to earn more probably right now if your agent is going to find this website and from him he's going to learn that okay if you're cancer then just write a write from a blue not kidding that that's what he's doing and please give my s address  00:35:04 The Admin: pen draw there and disease is fixedVenkatesh Babu D B: No, he's saying if you put black color there, you'll start feeling hunger.The Admin: Yeah. So I I don't want to understand also and I will not do it. Okay. You do not want at least your agent to do it, right? So uh please make sure that uh everything is grounded and your prompts have to reflect that and from banking medical uh insurance wherever money life is involved money life and life is involved you are going to make sure that you're picking a conservative strategy right so financial legal and sensitive systems you want control not creativity calculating EMI for 5,000 over two years and 7% and similar ideas then we have exploratory strategy now here you're allowed to use color theory Here you're going to pick one plan and uh out of four five different options right here you will allow the agent to run multiple strategies in parallel figure out from multiple places for example is it what is the best time to go to Gulmmer in India right now for that you will have to go to different websites and look at some idea and again we are not saying we are letting the agent hallucinate but there it is allowed to think creatively and come back with some interesting solutions and maybe read Reddit and find out that okay 15 July 15th January onwards there's some discount also or something of that sort right there  00:36:28 The Admin: we are allowing it to do a tool called rack query web search and compare the output of three four different things and then tell okay I think that's the right idea so here we're not asking our agent to be not careful here we we are providing more options for the agent to look at before we actually confirm when you are doing a for example options buying or a stock buying you want the agent to go on nse and buy the buy the stock right you don't want the agent to go on uh zumato and buy the stock that's not a great idea but In case of expertive strategy allowing you to find prices of different stocks at different websites and then try and see okay this is the latest one and I can report that. So this strategy is enabled by multi-tool dispatch where we can run multiple tools. I think in session 11 or 12 uh we're going to update our code base. So today we're going to introduce our agent which writes code but in the future one we're going to write let it write uh three different code and we're going to run the three codes parallelly and we're going to get the result and deliver back because running code is fast.  00:37:24 The Admin: like nanconds and no agent recall also. Then we are going to allow for a plan dduplication where the same plan can be executed again with slight change and we will allow for a devaluation where we're going to see the the result that we got from totally different options were similar and this one seems better. This is best for research agent. You're asking your agent to do research because you want to invest in a stock, invest in house or buy a particular car or vote we anyways give to one party or one leader. But if it was for school selection other things then uh you can use this kind of agent where the situations are there with ambiguity where you are also not clear where uh the result should come from where the agent is operating in informationrich domain where the you are sure that information this particular domain is good and for example you're asking it to work on only your rag or your company and you know the information there is not spoofed up example tell me about the Apple chip using vision pro in this case it doesn't have to go directly on the apple website figure out it can prefer multiple websites because information will be sort of I'm hoping uh correct in all of those cases and because we're allowing for multiple uh searches then it will get 10 12 different references and then come back and say that okay all of them are saying that A14 or  00:38:33 The Admin: A15 now here our agent is going to search internet for news going to do search for the memory which may be local which can be uh short-term as well it's going to search for documents and uh all at once right so that's the exploration we're talking about is exploring like uh Mckenzie intern like everything's being exposed at the same time it's capturing information wants to uh inspire his boss that he's the best intern possible that's the kind of agent we're looking at so this agent is curious it's proactive and it's parallelminded then comes the third one which I said in the beginning also that I tend to make the fallback Saturday part of conservative and uh exploratory both because there must be fallback what will happen as you're going to make more agents that you've tried to do something it fails after that just says that I give and I don't want to something fallback strategy itself is a strategy where if something fails something else open up and it's very boring kind but the moment you attach it with conservative or exploratory suddenly things are things can look different now here you'll allow your agent to do something else in the first one phase inconservative probably you'll ask the user that should I try something else in the second one uh for example you've tried to uh there's a patient dying in hospital the  00:39:46 The Admin: patient is dead now the agent's coming back to you and asking you want try something else to uh fix a patient you know that's a wrong situation right so it's situational as well but fallback strategy is something that is required something fails something else can be done it can be file failure it can be information failure it can be the API what all we wrote in heristics right what will happen heristics is going to see and just cut off heristics can't respond back you can't have heristics come back to the user and say heristics fail for the rule number 17 we may not that may not be the right idea in that case we'll let the error know that um the password is not working for for Gmail and you have to respond back or the shoe that you're trying to buy is for 6,000 rupee and you have 5,000 rupee and probably should buy something else right so that's a fallback part now here this single line essentially makes it uh fall back uh applicate or fall back the features added just by single uh this single line which is the max lifeline tries is three so how many times we have to that fall back is something again will depend on your use case but I've I found three to be the uh good number where if something is failing failing it essentially  00:40:56 The Admin: wins up so it's and it can happen for a part of the problem or it can happen for the whole problem now when we're doing something like this max lifeline equal to three so one single prompt agent goes through and does something if it fails the prompt is injected with information that you failed last time using something like this so don't try it again right so now it tries new way if it fails again then the third attempt that's a fallback simpler uh definition of fallback okay now in our case this part was already implemented if strategy is conservative we'll have a single plan if strategy is sort of exploratory the run par plans and if strategy is fall back then we'll have try plans with retrieves but you can actually add fall back to any of these other strategy as well to make sure that you have a cohesive single bridge strategy now in your loop py if you just fire up the context agent profiles strategy. It will start going to give uh life back to your agent. But now let's go to code and see this is not your code.  00:41:57 The Admin: This is your code. Let's look at prompts. pump here the pump and uh so let's alt z as well here right now we're reading decision prompt which is conservative you are a reasoningdriven AI agent responsible for generating a simple structure executed plan execution plan using only the tools currently available to tool catalog. Some tons of tools are going to come here. User query, some query is going to come here. Goal write a valid sync a sync python function name solve. So I told you right this time our agent is going to be writing code. So any problem. So it's actually going to solve it using code. In the next one we're going to merge this that everything doesn't need a code. Everything doesn't need a hammer. Sometimes even words will words will do. So we'll mix that in the next session. But this session whatever question you're going to pose your decision is actually going to write code for that. And later on we'll have a code agent separately as well.  00:43:03 The Admin: So write a valid a sync Python function named solve that solves the user query using exactly one function call. Now here are the strict rules. Plan exactly one function call only. You must always define a function as a sync def solve because that's how we are uh trying to find the program and solve it at our end. Each tool call must follow the usage usage syncing format. Exactly. You must call only those tools that are available in the tool catalog. Call a tool using its tool name string not function variable. For example, await mp call addin input not await mcp. callall add input. Right before each tool call, paste a full tool disk talk string enclosed interle quotes. Call a tool exactly as per function signature tool input. If one function call depends so it's a long prompt, right? And I'll not go through the whole thing but there examples of how it is supposed to write function or it is not supposed to write function. Right?  00:43:54 The Admin: There are anti- uh examples as well. All of these functions are already there in our MCP and it's a long prompt. I wanted to uh also notice something. I'm going to do control A. I want you to notice this. What does it say?Ritesh Verma: Three characters selected.Venkatesh Babu D B: charact.The Admin: 6483 characters. And along with that, we're also going to be infusing our tool description and user input. That's a lot of characters. And the prompt that we're going to write in the next uh session is going to be literally uh half not even half 25% of this. This is the prompt that's working but it's like a very good example of how prompt should not be written. It's a good example of how prompt should be written but it has so many mistake that that is actually being made very very long. So we need to fix that. Then here we have exploratory parallel right in this case again something similar but your reason given AI agent responsible for generating a structure execution plan using only the function tool available you are write a valid Python code plan two to four function calls that run independently inside solve right so now you're saying that you can actually run two three different function calls inside one function itself right so a small chain and I would like you to  00:45:15 The Admin: uh basically read the promps or use some tools tools to identify differences in them. Here you must call those tools again but here what is going to happen is that here we're allowing sequentially. So there are three uh decision agents here. This is conservative. This is exploratory and it can create function that run in parallel. This is exploratory that create functions but they don't run in parallel. First one runs if the first one fails the second one run the second one fail the third one run. There's sort of fallback also involved in this right. Okay. So, I'd like you to go back and uh take the code and read it up. Okay. Yeah. Y. Now, if you go to code uh config, sorry. If you go to config, you're going to see two files. One is the model.json. Here we're describing all the models that we're using. We're using Gemini Flash. We're using Olama fee and other models like GMA.  00:46:16 The Admin: And then we have this profiles. So to move uh strategy from one to another, you will have to come here and change your uh planning strategy from conservative from conservative to exploratory. And if it is exploratory, you want parallel or sequential that is only relevant if the planning mode is exploratory. Then this memory fallback enabled, I've kept it true. So if the tool fails it's going to go back to memory and remember that that tool failed and identify the max steps kept here is three and that is for the expiratory strategy right so and max lifeline is the overall number of steps max steps is for the parallel how many parallel or sequential steps we are going to try max lifeline is how many times we are allowing the agent to overall run right so that essentially describes the whole agentic flow and works with uh our system uh right Okay. Now, decision trees and LM chaining with Python plans. There's something called function piping in uh or piping functions in Python where you can run a function and then immediately second function and third function and we can essentially send output of one to another and another and we can write it in such a way that three different function call essentially becomes one function call.  00:47:31 The Admin: So the code that we've written is actually in that format where our decision agent in the explorative phase or in the parall or in the sequential can write the chaining prompt. So now if you ask for example uh what is the sum of the exponential of the sky value of the word of the characters in India it will not have to run three function it can write one function it the within which the functions are piped and it can achieve something uh in one instance. So it will actually take just two steps. One step to understand what is there. Second step to uh basically run the tool and uh first step to understand what is the problem. Write a code to run. We run the code provide result back and the second step it basically answers what is the sum of exponentials of uh the sky values right so that's the that's the lm chaining and lm chaining with with python essentially and the same goes for decision tries also decision tree is going to become our main uh focus by the time we are in session 16 and our final architecture is based on decision tree we're going to be leveraging a tree structure a graph structure our agent is actually going to be a graph.  00:48:38 The Admin: The final one, the final architecture where u the first agent is going to decide what to do create a plan and the plan itself is a graph and each graph node is a separate agent and that's how the 10 agents are going to interact with each other depending on where they're required. But till now why this is important because till now we have passed a query we have picked a tool we use and we repeat it but the problem comes here many real time uh real world task are going to fail they require chain of actions they need validation between them as well more many times the logical step after a and b and and after b c but currently we're not doing it we are letting the lm think that after a it is going to see the result and it's b then b is going to see the result is c and so on cursor doesn't work like that when you work with cursor and you add a prompt I write a function to do something like that. It's not going to say write the first thing and wait.  00:49:27 The Admin: Yeah, correct. Then second and then wait. Yeah, correct. Then it's not doing it. It knows that first five six steps are these and I'm going to do it then I'm going to pause and I'm going to see the result. Right? That is required. So basically not just do the step A and then step B. You will do a step a check if A work then step B and else fall back. Right? Those steps are also in between for heristics to check not the element to check. So from steps we again moving to strategy. So again a repeating theme today from a plan we moving to policy from steps we moving to a strategy. Our code today is not I'll say rich enough or doesn't have the foundation to able to be able to do what we're discussing where it can create tree and work but we can achieve that through simple loops. Step one then step two is step two fail. Okay. Then try step 2 B and then it fail.  00:50:14 The Admin: Okay. Try step to C and then failed. Okay. Try step two D and then work then three. That is possible today. So let's look at a simple request. Find the ASA value of characters in India and then return some exponential of those values. Now to solve this the agent must first call strings to cash to int validate the list. Then call int list to exponential sums and then return the uh return the result. Now that's not a pro uh a plan that we want the agent to guess and go through multi steps. It should be explicit. It should be Python. Right? So there are a lot of problems that can literally be done through Python. So if you take this and uh you send it to a agent that can write a code. It can literally take those these two function and in one function called can just finish it. That is how we going to be uh that is what our decision is actually doing right now.  00:51:00 The Admin: So now we're going to ask LM to propose a plan like this. Define solve and as you mentioned in in the front it will have a sync result one is equal to call strings to care to end. This is the input if not result one or output not in result one or not result one of output raise the value error the sky uh conversion fail right so we're asking the agent itself to come back with the error and second is if that happened so if we did not enter this then the result is going to be called int list exponential sum and input result output and result two is done right so in one single step it will solve all the problems that we are solving now the credit of thinking that lms can actually write code and execute and and can actually be better goes to hugging trace and they're doing it for quite some time and I agree with them on a lot of different scenarios that coding agents are actually better and uh they call them small agents and they did a full research also they have a paper on this as well there are some tasks that were uh provided determine the most cost effective country to purchase a smartphone model code act one.  00:52:13 The Admin: The countries to consider are USA, Japan and Germany and India. Now LMM that is not using the code is going to do something like this. I should calculate the phone price in USD for each country then find the most cost effective uh country text lookup JSON lookup this is a function called going somewhere 1.19 lookup phone price code one Germany and so on. This is how it's running the most cost effective country for purchase and business. Whereas code act and LM that can write a code I should calculate a phone price in US for uh USD for each country then find the most cost effective country. Countries are USA, Japan, Germany, India final price for country and countries exchange rate blah blah blah blah blah. This guy didn't even look at the exchange is coming here right looked at everything and that's it. This is the answer right? So way less number of tokens, way less number of calls and much faster and grounded also because now it can actually tell you that this is where this is why I think this result is correct.  00:53:09 The Admin: Are we clear? Can you start seeing the opportunities where your uh code if the whole decision was code agent can actually work? finding something, looking up something, summarizing something, writing a code for something and uh processing a particular problem, processing a math problem. All those things can actually be solved in a very very well defined manner. But problem is we can't do everything with code agent. Sometimes we for example summarization as I mentioned for that we need an LM and there's no code it can write if you force your decision which is why I have not introduced the non uh code agent in this assignment. If you look at a code, it can just write code. You given a prompt, the perception is different, but decision is not moved to writing code. It will just write code. So now if I ask you to summarize something, it is going to call a function a function and say that uh summarize this text and the function doesn't exist. Right? So code agent alone are not good enough.  00:54:03 The Admin: But they add a superpower to our overall framework and because of which we can actually get rid of lot of different uh functions that we wrote at RN. Right? It's a very good introduction of what code agents actually are. For us is because of our format because of the way we are writing our uh agent library. This is a very simple structure but otherwise there's a full library that you can actually use for achieving something like this. Okay, Satish.satish jasthi: Rohan these code agents they are just a small agent a small LLMs or they also have prompt using which they generate code like this is it like so the conservative promptThe Admin: Of course prompt is there. I just showed you right. No, all the prompt all the decision now is a is a code agent.satish jasthi: okay so it's internally using basically picking based on the user uh query Okay.The Admin: Correct. Perception is going to tell the code agent or decision that this is how you should think. Now so the idea originated from here and I felt it's a extremely good idea and that's why it's a part of our uh overall architecture and as we're going to come close to our final architecture you're going to  00:55:06 satish jasthi: Okay. Okay.The Admin: see that code agent is not only going to be helpful for writing Python code to solve scientific problems or problems that require quantitative analys quantitative analysis. They're going to be super helpful for writing HTML code also because sometimes you're going to see that you want a output where the file is beautifully formatted. You want it in a particular format. For example, you're making a report for Mckenzie. Maybe use Mckenzie font. We use your logo. In all of those cases, where should I place it? How should a header should be or making a small table or a graph becomes very easy for agents especially if they can write a prompt, write a Python code. Are we clear? Uh Sachin of of course here you can see the example the response this is the response but in the response it's calling a function.Sachin Bharadwaj: Now when you say code agent I mean I mean it's like the code agent can also uh talk to the external APIs or tools and and invoke MCP and so which this means uh it's I mean uh the dynamic plan planning is done by writing a code right that's what you mean talking.  00:56:18 The Admin: Correct. Of course you can.Pratesh Kumar Reddy R: Yeah. So can we extend this further and just ask code agent to write the code for strings to care to int and in so that also we had to decide like to what extent we can uh allow it toThe Admin: Yes, of course you can. That needs to be the part of your prompt. Here we are saying you must define a function. Plan 23 function. We're looking at exploratory. Okay, let's go to conservative. Plan exactly one function call. You must always define a function. Each tool function function call must follow the particular usage. Call a function tool and so on. Call the tool exactly if one function call depend other pass the previous input. You never use inline your function return blah blah blah blah. Right? So here we're not saying that it cannot write its own function. So it will be able to write its own uh function also.  00:57:14 The Admin: But if you specifically say here that you're not supposed to call any function or make any function then uh it will not okay.Pratesh Kumar Reddy R: Okay. Okay. You got it.The Admin: So what you're seeing on the all of you please uh just for my sake uh tell me that you know this is the output of decision. Please tell me that you understand that this is the output of the decision agent where the agent is giving us the code to run. Now this code is going to go to our sandbox. In the sandbox, we're going to run thing and whatever result two or result one is there. We're going to provide the answer to whatever is waiting for the answer. Right now our decision does not respond in text. It responds in a code. That's the idea here. So this is not a prompt. This is not the text output. This is literally a Python code that is going to be written by the agent and the code is going to run in your sandbox.  00:58:18 The Admin: Are we clear? All right. Now, how it is going to work behind the scene is we have already discussed but let's go uh slightly more detail. The agent is going to receive a complex input. It's going to get something for which it needs to write prompt, right? Uh need to write code. If multiple tools are involved, it is going to create a solve function with a validation logic. It is going to output a plan as Python code. The code is going to run inside a sandbox and the call is going to be injected in the safe API for execution. So this is what is happening in the background that is already written and codeish on the platform already. So the call API in the sandbox in the sandbox we're going to inject. We are going to make sure that the valid tools are there, the valid schema is there, the log call is also there for introspection. So we are telling back what happened and we're returning a result.  00:59:07 The Admin: So these are four thing that is happening inside the call right. So the call is going to be running inside the sandbox. Sandbox has already been declared that these are the function that it can't call or these are the only libraries or modules it can use. Apart from there in the call itself we're going to make sure that the tool was allowed tool is a part of the allowed list. The validate the input is valid validated properly using pyandic for that and the log of the function what is happening is being injected out from the sandbox. So we can print it if required. We are doing that and we're going to return the result of whatever uh issue that arise and we can raise that problem also. So how we have achieved this? We achieved this using making sure that tool is in the current registry. The name is mentioned the arguments are validated using Python pyantic in the models file. As you might remember there's a timeout for for execution also which is 20 seconds 10 second depending on which function you want to uh uh focus on.  01:00:03 The Admin: The result schema is also checked and we are allowing maximum three calls uh three function calls per script. Right? So it can write a one function in which it is adding three functions and we can achieve that. Now the Python plan matters and you would need to think deeply about it because that will give you way more idea. For example, the tool output of a small mal formed a traditional flow will be the LM will fail to detect and say that tool failed. It has no idea why it failed. But in our case, if the tool actually failed, we can raise and retry, right? That can happen internally. That is something that we can assess Python code with. Let's say there planning drift element forgets the previous steps. In our case that we are plann all the whole plan is a part of the code code can't forget right now let's say you got an instruction in the morning the moment you woke up in fact you have woken up and said bahhatcha immediately get milk kids have to go to school so get Maggi also I don't have anything to make for the breakfast so get subji as well and while you're coming back make sure you have paid the u the the shop the last week's money also now you're so scared in the morning when you woke up you went out you went to the shop you paid the money, bought the milk and came  01:01:09 The Admin: back. You forgot oil. You forgot that uh your kids were about to go to school. So you had tea in between also and got your haircut and maybe some nose haircut also. All of that might happen, right? But if it was a code, the code was very simple. The code would do step A, step, B, step C, D, E, and it will not forget. You are not letting the the task to go back to the agent to for it to forget, right? The tool calls are the agent calls are less. No, you reuse the same tool is used twice unnecessarily. Agent tries to do something, doesn't happen. What does it do? tries again doesn't do try again doesn't do but in case of Python it can create a plan a cache it will remember the last I have used this step recently right that is a part of a code missing validation an agent might over trust output right say that okay output looks good I'm happy but in Python uh we can test whether output was good or not and it can execute accordingly that's why the Python code uh generated by the agent and running in a sandbox is super important uh Satish  01:02:06 satish jasthi: Rohan here uh the reuse part right like because the whole decision is code uh if we break it down into smaller chunks and can we cache those also like there is a problem and there are sub parts of it whenever we have to use the same subp parts in some other problem so it will reuse rather than running it okay uh yeah I think it depends on inputs also yeah my yeah thankThe Admin: Depends on how you're writing it. Correct. Now here are the real world use cases. The prompt is extract images of PDF and caption it. Plan can be simple. Extract PDF images and run OCR image on top and provide the result back. Search F1 standings and update Google sheet and email me. Search document. Write a sheet. Send email. Right? All of this is one single plan. Now fetch PDF from Gmail and answer what's in it. Fetch email, summarize PDF, answer question. All of these can be executed in one single step where you can use either a small LM if required or maybe just pure Python code to execute all the stuff right that's where the power actually comes from.  01:03:09 The Admin: So these are not workflows these are workflows these are not steps and Python is how agent describes them. So Python is a language that agent uses to communicate with the sandbox. Now how do we prompt the LM to plan? We're going to be using something like this. If this task require multiple tool calls then write up complete Python function using call tool name validate output as needed we and use if check uh if checks to avoid broken rule change and the agent is going to reply with the code. Let's look at an example. Okay. What do we see? It's done already. Okay. Uh what do you see? Here is what we want to do. Right? I'm printing it multiple times. Okay. Find the asai values of characters in Indiana Jones and then return the sum of the exponential of those values. Now, step one out of three. The raw JSON output is this is what perception output.  01:04:40 The Admin: Are we clear? Okay. Perception is supposed to provide four things to us. What is the intent? Intent is to calculate the sum of exponentials or asai values of characters in a string. ASA entities are asai exponentials Indiana Jones to hint Python sandbox and selected server math. Okay, this is the same result. So uh the log is printed twice. Then the perception output and the query goes to our decision agent. And this is the code it came out with python import JSON async def sol function call one. It is writing this and it is taking it from my uh mcp file. Now what was happening when I was writing this code was that it was failing. It was not able to figure out the right uh tool. Sometimes it was picking wrong tool. Sometimes it was picking the right tool but it didn't know how to call it also. So I was I just I've just forced my in the in the comment section in the prompt to just write boxing again.  01:05:41 The Admin: moment write proxy it automatically understands oh this is how I'm supposed to use it that's what we're doing here so it is saying convert characters to ascar values so input here becomes Indiana Jones result await MCP tool call strings to care to end it's actually calling the MCP and it's getting the output from there and the results are stored in the numbers right it knows exactly how to read it then we have a function called two some exponential int list again writing dock string calling it and the final answer is here then we have a plan Uh this is printed twice. Okay. Final result detects all plan now. Okay. Now it is entering the sandbox. This is the raw output again printed out and final answer is mentioned here. Are we clear? The log is printed twice because of debug. So all this is happening in that same function call. You can see that how many times it had to run. It ran literally two times. one for uh generating the code and second actually just to say this.  01:06:46 The Admin: Nas always happen irrespective of what?Nawaz Ali: Rohan. So the LLM is being called and then it is taking the decision of converting it into a Python code or it Yeah.The Admin: Okay. Perception output and query goes to our decision. decision is told that it can only write code or give final result. It looks at the query. It looks at the perception. Writes a Python code. Python code goes to a sandbox. I'm sh box sandbox provides a result. This result post decision along with the original query and it just prints out the result. here. I'm not as of now.Amlan Routray: uh uh so the tools that we have is await mcp call tool so we do have these tools in our action uh the tools py right and and uh um we do not let so the code that weThe Admin: Yes.Amlan Routray: were writing uh ourself to call this tool is now being handled by the python interpreter okay Yeah.The Admin: Is now being handled by the Python, right?  01:08:06 The Admin: The phone call is automatic. Now that's it.Rajit Badgandi: What if we were to employ memory for something right as part of that flow? How how uh so we we give that as a context to the LLM to generate that respective code.The Admin: It's going to be it's going to be a function that can query memory or part of the uh rag. Rag rag itself is a function call. Uh no we we have already we have already done that. We have told it that here a tool catalog. So it will have a tool that is called memory something or rack something.Rajit Badgandi: Okay. What?The Admin: I'm done.Amlan Routray: Uh so the overall uh gain in this uh way like implementing this thing is like rather than like calling the uh making tool call or LM calls thrice we are just making one plan right then what's benefitThe Admin: Uh no no uh no because what you said is not the only benefit. For example, calculate the hours in strawberry. Now this is something that LMS have failed for years.  01:09:13 The Admin: Now they fixed it. But now the way they fix it is also interesting. They're fixing exactly how we are doing it. So if so what we're saying is that if you think that writing a code can solve this problem in a better way, write a code and there are many many problems with that.Amlan Routray: Okay.The Admin: That is not our prompt by the way. our problem right now that you have to write the code because I also want to show you that if we try and solve everything by code it's going to fail that's why that's where we are in the nextAmlan Routray: Okay.The Admin: one we are going to allow it to either write code or either solve it but today we are enforcing it just to see the pain of just working with code as well so it's powerful you can solve a lot of problems but the problem is that that's not the only way to look at problems all right so there is building safety already uh we know what tools are supposed to be called.  01:09:48 Amlan Routray: marker. Thank you.The Admin: The inputs and outputs are out automatically checked. There's a timeout of 3 to 5 second per tool called there is no import no exec as of now which means our agent right now can only use a function that we have. So I've also limited that particular fact. So our agent can't write new functions. So if someone was asking can it write exponential answer is yes but currently based on the prompt can't uh it can because I've not specifically mentioned don't write any function but it can't call math dot something. So those features are essentially disabled as as of now. Okay. Okay. Questions on this before I move. All right. Now we also have to have adaptive planning loops. What does it mean is if a tool actually fails agents are actually going to fail more and agent may be perceiving it may misremembering it may misreason it may misact it can actually cling to wrong plan as well and that is where we actually start seeing the problem in our agent and when you're writing agent to solve particular problem it's not able to do it these are probably the reasons so we need to make sure that we understand that we have acted against this.  01:11:16 The Admin: So let's look at the reasons actually agents fail. They misinterpret the input, right? There's a person sitting next to uh next to you when you were young on a chair on an aircraft or maybe a train of opposite gender and just did this to you can take it in any uh can misinterpret input, right? Not a great thing. So you just misunderstood the user's intent to query, right? Or someone said hired. How many times this has happened to you and be very honest. Somebody really smart said hi to you from a distance and you thought the person is waving at you and then you realize there's somebody at your back or the person next to you. So again misinputting the input right and uh then we have in for example you get a phone call around your lunch time when you're in office and uh you get a message we need to talk right you are like you have no idea how to interpret incomplete perception you're missing critical information or signals someone's looking at you for 10 seconds if you're not understood why the person looking at you very bad you need to know that you messed up poor confidence right you booked off hotel or restaurant where you think everything is fine and then you realize that it is thieves stay when onion is not allowed then it's a problem.  01:12:35 The Admin: So assuming it's first outputs correctly without checking not a great idea insufficient memory recall that happens to all of us right we don't remember everything we forget of previous context or history right that happens to all of you then retrieve error retrieve wrong information or irrelevant document right again bad thing to do where were you last Friday and then you I was with my friend's home and then you realize oh you're again lied wrong tool selection you're picking an inappropriate or outdated tool not a great idea tool misuse using the right tool incorrectly. API failures, timeout, the tool back end fails and delays the response. Mal for tool outputs. Tool outputs is uh syntactically invalid unexpected. Then assumption to drift now continues based on assumption that uh is invalid, right? You're continuing to uh call someone, send gifts and flowers assuming that something is valid but it isn't it isn't anymore. People have moved on. Then the poor plan generation creates an ineffective or over complicated plan. I will finish my engineering. I'll get a job for first year 40 lakh.  01:13:39 The Admin: Second year 50 lakh. Third year I'll do good 80 lakh. Fourth year around 2.5 cr. I'll buy a house and wrong plan. Bad prioritization. Uh first I'll get married. No, first I'll have kids then I'll get married then I buy a house. Extremely bad plan. I solve the easy part first. Was a critical failure. Now missing edge cases doesn't account for a rare word and you see that it's a long list and this is something that I was able to come up in like five minutes if you think about it and if you ask with your with your charge GPD or something uh similar you will come up with all of this two ways to solve this one is heristics a lot of things can be solved by heristics that's why it's very important you make sure that heristics is part of your overall uh overall plan heristics something that you will not find in other platforms they assume that you would take care of heristics yourself right so even if If you were to use other things, they just add pyic and assume that everything will solve using pyic.  01:14:33 The Admin: Not true. Right? So there's cyclic behavior, there's premature abandonment, there's lack of fallback mechanisms, there's failure to learn from pri prior attempts, misalignment to you uh with user goals, external environment changes or internal errors, bugs. There the there are only few of these I've mentioned here. There the list is really big, right? To make sure that you have a extremely solid fallback if any of this happens. And when you're going to be making uh these agents for your company or for a product that you want to sell to somebody else, you have to make sure that all these are taken care right it's a software engineering software architecture that you're trying to learn which is sort of dynamics right the principles are not fixed no one can write a single book on agent and say they're done not possible because these are dynamic cases these are it's as good as saying a book to understand a human not possible based on the input output changes you have hit four speed bumps on the road today uh somebody hit your car at the back you are going to be pissed off in office there's no way anyone can predict it and that's where LM also are LM also going to be behaving very weirdly okay so what is an adaptive planning loop at the core agent  01:15:39 The Admin: is going to plan a step it is going to try and execute and one of this will happen and one of the other 81s that are not mentioned here right those are the uh reasons because of it can fail if the tool fails it tries to do something so it is very important to understand that something has failed, the tool has failed or the results are not up to the mark. Very important to understand that we have failed in doing something because moment you understand we have failed then only we can proceed and do something else. Same thing applies here as well but only with a controlled retry budget we will not continue to try for example that's why we have a limit on how many times we can give CAT or even IPS exam right and in our case we are looking at three as a good number to start with so the key principle is that we're providing control flexibility unlike explorative strategy which tries multiple tools in parallel adaptive planning is about falling back intelligently and sequentially when the primary path breaks Please understand this course is more about you understanding how to write an architecture for an agent because it is not fixed what kind of agent you're supposed to build after in your afterlife in your after the course life right it can be anything let me give you five examples and actually ask you to think about it let's say we need to write an agent that plays in stock  01:16:58 The Admin: market and the agent A is there and then we have agent B is there agent Agent A is going to invest in stocks for and is going to do long and agent B is going to play in options. What do you think you're going to do? Do you think the architectures are same? Extremely different architecture. You cannot use what is happening in long and apply that in short. What is long by the way? Anyone?satish jasthi: Equity curve.Arpan Das: You buy.The Admin: Buying buying shares. You buy shares for long, right? You're buying for not one day, not two day, for long. There you're going to see a balance sheet. You're going to see revenue this quarter was higher than the last quarter and the uh results are good and blah blah blah. And then you're going to pick a share. But that's not how we pick a share. We pick a share because your friend or your brother told you to anyways. But that's the probably the right way.  01:17:51 The Admin: We buy shares, right? We'll do full analysis or at least ask our agent to analyze, right? What if your agent comes back to you and uh tell you that I think you should buy a lens card because Geminina was telling me you don't want don't you don't want your agent to do it right. So in option A we looking at long shares in option B we are looking at options. Now what are options anyone?Arpan Das: basically derivatives rights to buy or sell uh based on your like on a timeline on future.The Admin: when what what's a timeline?bhavya kamboj: At the point in future,Arpan Das: Again, there are different options traded at different timelines.The Admin: Okay, so let's simplify that. Let's say we are a we're talking about a day trader. Let's forget these two. Okay, so we're long versus day trader. What is a day trader timeline?Arpan Das: OneThe Admin: One day is very long actually is instant mostly for some for a lot of people. Right now, day traders work on principle that they're going to be making 0.5 to 1% max in a day.  01:18:50 The Admin: Here 1% you're going to be angry. I invested for 1 year and you get 1% back. No, but here 1% is a big win. So these guys wait for 476 becoming 486 and exit. Right here it's fast and you don't care about anything. What do you care about? You learned that today we have Modi and Rajnath Singh. They're going to go on stage and they're going to say that they're investing one lakh cr in defense and out of that let's say 75% is going to go on drone. Moment that information is about to come out. You know that you're going to buy uh stocks that are making drones and you couldn't think by that as the news comes out you sell that. That's not a long-term strategy. long-term strategy would be to realize that okay they have mentioned it then they're going to take five years to clear the budget and after five years they're going to take five more years for the uh the plan to come out after five years they're going to say okay this is um how you have to make and after that they realize that 95% of the budget is going to go in someone else's pocket the company is going to get 5% rupees on which okay the growth is only going to be 5% in five years or 1 2 3 15 years that's a long strategy are we clear where I'm going with this is I want you  01:20:09 The Admin: guys to understand that the code that I'm sharing with you is an expression of how a particular problem can be solved. I wanted to look at the architecture out of it. That's how today's assignment is also structured. I wanted to understand that based on the problem, you we keep on changing the architecture. So I wanted to become architecture experts here. You're writing the architecture of a software. So let's just find bucket. So another example, one plan, two fallbacks. Summarize this PDF from Gmail. Now we're going to fetch the Gmail and Gmail comes back with Gmail code exceeded. If that happens, we're going to still try and see whether you have that PDF in your downloads or somewhere else, right? We found an old update. Okay, old upgrade was there. Then we'll summarize that and we'll mention that okay, I couldn't find the latest one, but the old one is this one. That's how proactive we want our agents to be. Right? Agent has not panicked here.  01:21:01 The Admin: So, and that is happening in the loop or strategy. In there we're going to decide which tool to use next. Whether to abort or continue uh when to switch modality from tool to memory to code. Now, how does a tool switching happens? We have hint based alternatives. We have not implemented this yet. But when we're going to save our memory, see human memory is very contextual, right? Contextual. uh you went to a restaurant your food wasn't good you have saved that so imagine a restaurant that you don't like right or imagine a restaurant for you we've ordered food and you don't like or a food item that you don't like maybe so there are food items that I don't like and there very few like two three only like bean gia tinda ari tur uh gali same I don't know you know all of these are not but these are only two vegetables I don't like but moment I think of these vegetables Hey, my like whole body shiver like I bangan. A few people like I know eggplant a lot but I just find it weird that it's slimy.  01:22:02 The Admin: There's no taste that goes inside. It's like it's like slimy penetration of radioactive material where no salt, no masala can go inside and change the taste. So that that's the feeling I get. Right. So human memory is very different. We have all these context around it. But our memory the way we're going to save it is not like that. We have to make it like that. And that's where these hints are going to come. Bad food, bad URL, good URL and very good URL, right? So, and high confidence UR. So, we have to save all of this. So, memory cannot and that's why we have not touched on memory because it's not just saving chat history or simple lines. memory is way more contextual and we have to add these hints to that memory to make sure that if in future we reading it we understand okay product A these are the things that I need to remember when I remember product A for example I'll just use two words and think of the things that come to your mind silver apple moment you connect these two things a lot of things you can remember and realize right and that's how we want our memory to be so First is hint based when we are actually going to do a tool switch maybe perception can come back to us and tell us that you tried uh um Dr. Why  01:23:19 The Admin: don't you try Google or why don't you try some other chat or some other uh uh search engine? Second is memory aware. I can go back to my memory and check that okay you asked me the same question last time and this is what I did. So we have some option there. Then we have sandbox script. Uh I can actually write a code to check it out also. So you have many options fall back now. Right? This is how I think uh your tool may fail. What do we do then? Right? And the you have to come up with different options but it must be bounded. It cannot be infinite search right. It's it's not like you're calling someone that when are you coming coming right? Most of the times when painters are coming to your house or let's say the AC technician or your maid made are genally mostly on time but whenever painter is coming at your house or mason or someone and then do minute is like two hours and we don't want that that's not adaptive.  01:24:11 The Admin: We want to have a certainty that it will end. So here we are limiting oursel to three. Three is a really good number. like three kids, three houses, three cars, three jobs, three loans, three emas, all of them are good. Uh you only have three lifelines. We have three lifelines if you actually think about it. Uh childhood comes twice. Once when you're a child and second time when you're going to be old. Old person is like a child, right? You are going to become a child uh in 20 years probably 30 years. And uh those are three lifelines that we have. Okay. So the strategy profile integration fall back is required. Conservative agents are going to stop at the first run. Exploratory agent will have multiple option to test out. Right? And that's not fall back only. Exploratory means that Google search, local search and python code and other stuff, right? That's exploratory. But you can think of it like fallback.  01:25:04 The Admin: If Google fails, I will do this. If this fails, I'll do this. Whereas an exploratory uh again coming back to real life because uh uh you can maybe feel more out of it. There are friends in your college who were in exploratory phase right and they will go out with five six people and then figure out huh this is the right person. Then there are people your friend maybe you also who are in a fallback agent mode. If this doesn't work then I'll find somebody else and then uh see if that doesn't work then I'll find somebody else and see. You had the heartbreak for two months. You were sad sitting on a chair listening to Kishar Kumar. The other person had five things going on. Four failed. One was still on. Never had to hear sad song. Right? And then there's conservative. The first love failed and the guy said done. My life is over. Right? So which agent you want to be.  01:26:00 The Admin: So decide. Okay. Now then we can use the memory to modify the plan also. But for this as I said a memory module has to be really strong. So we're building the foundation for that. Till now we have looked at the current input. We planned what we saw and we're reacting without a historical context. But if the task is solved before if the tool has failed for a similar query for example you're trying to extend API and that's not working and strategies that work for a specific time type of inputs already. A function worked for a particular kind but it didn't work for something else. uh traffic worked for nse but did not work for some particular other website and uh go worked for uh BBC but didn't work for NS. So if you keep remembering all of that then actually becomes smarter way to handle things. So true intelligence is just not actually about reacting it is actually remembering and adapting and evolving the tool calls and function calls and retrieving from memory.  01:26:54 The Admin: So that is where you're going your agents are going to becomes from stateless to stateful. Remember our architecture will become stateful. Our agents of the the LMS at the back end will always be stateless because as I said you will not be able to host your agent on Gemini forever. If that happens future perfect where all the data everything is saved with Gemini or OpenAI and it can remember everything for your agent not for your account. If that happens then perfect but otherwise at least we're trying to make our overall architecture stateful which means for each function call for each memory retrieval we are storing something and that allows in the future our agent to learn from the previous mistake adapt the plan based on memory and decide a tool call based on how it performed on something else. Now what can memory teach the agent? It can tell avoid or fall back. It can offer a guidance and can actually just copy the last two chain. Last time this question was asked I did step A step B step C and that's all.  01:27:52 The Admin: So I just need to copy that and paste it right you can get read a whole log. So that's where the benefit comes in. So a simple example planned adapt adaptation for example summarize today's cricket match if in the memory search documents hint cricket match success to result before and prefer search document first the past failure search memory or guide the user to the external use link. Right? So if it is in memory and somebody asked today only that uh to survise today's cricket match it's a quick search. If it is there then I'll I'll look at it otherwise I'll move forward. Now how do we implement this? So for each tool execution we have to store a log intent for summarize cricket match entities work cricket and match. I use a tool called search document and device successful. So every time we're going to be calling a tool external tool our internal tool we have to store a log like this and that actually builds the overall statistics of how the tool behaves for a particular problem.  01:28:43 The Admin: Right? It's light compact and not heavy dag. Then we have a lookup for a planning table. Now before a while planning we're going to see recent tools memory get recent successful tools. It is important that okay see okay here we have called 100 tools and we are storing a log of it. Here we are looking at the recent successful tools. So we keep prioritizing those tools that are successful. Right? The again it's a sort of a heristic or sort of a I'll say an analytical way of calling tools where the tools that are failing often we are not calling them right again based on statistics this is going to happen and third is update after each tool after a tool call was done we are updating the memory to add tool call and this is what happened so your memory is going to be an extensive uh set of how the tools were called whatever saying back what heristics was useful uh which tool chain was called all of that has to be saved somehow.  01:29:40 The Admin: Now I'm sure you can over over a period of time understand the benefit benefit of this. Right now we're making very simple agent. So this will not be a complex thing but uh think of it like this. Uh somebody did that. Uh I will not be able to recolct somebody showed me a new model. Ah this only Gemini where are we right now? Gemini 2.5 right?satish jasthi: We areVenkatesh Babu D B: 250.The Admin: I think it was Apple OS. Yes. I'm not sure if you've seen this. You've seen this. Gemini 3 runs full Mac OS simulation in just one HTML file. Oh, there's nothing. Okay. Oh, this one. Can I see Safari is also there and notes are also there. one single prompt it may be fake completely fake also I'm not sure okay so take a picture with a picture of salt because uh three is out and other people also know but this is what is running right now okay it's fine this is fine this fine it's fine this is something that you will come up self.  01:31:57 The Admin: Perfect. Perfect. Perfect. Okay. Now, I'm skipping some stuff for a reason and the reason is this. Okay. Now, today's assignment is slightly different. The whole code that you have seen here and I'm going to show you some part of it. Uh, VNV, you know what is VNV? Config file. We have model and we have modules. Then at the core we have the context py it's doing something we have a loop py it's running the loop for the agent then we have session we maintain a session then we have strategy this is where we actually define the strategy we're picking from the yaml file what strategy are we picking and prompt is getting added here then we have set of documents where we are running rack then we have fire index that you're already aware of then we have memory where we are storing the memory step by step this is how the memory is actually stored okay and Then we have modules. We have action that you already are aware of.  01:32:54 The Admin: Then we have decision that you're aware of. Then MCP server memory. This memory py model manager which is handling different models for uh Gemini versus other stuff perception and then the tools that we have. Okay. Then we have set of prompts and env.I which I'll not click again. Set of logs empty file. Okay. Now your assignment is different this time. This time I want you to describe the architecture in full detail. Right? So I've shared a code. This last step is something that is literally uh the code described in a in a text format. What is it actually trying to do? But your assignment is to go through the code and try and understand architecture. How is the architecture written? What is it that uh the action is doing? What is it that the decision is doing? What is the role of loop there? And I want you to hand draw it. You can use some app also, but my preference would be that you'd actually hand draw on a piece of paper, take a photo and then upload because that will tell me that you've actually done it.  01:33:58 The Admin: You can get somebody else to draw it for you and then you can draw that back on a piece of paper. That is also fine. But then it's going to be so clean that I'll know that you're cheating. Right? So this is a very important assignment because the small small parts are added there where uh you need to make sense of it. If I take you through a code, you'll just not understand it. Right? Right. So that's the this is the most important part of the assignment. Understand the code what all is actually added inside. Now there's one bug and I I'll show you that bug immediately by running this site is not a command. Right. You have seen search Dr. Go. And now you're seeing some results. It's getting something. Right now it's starting search store document input course query unmolding DF cap payment. Uh right now it has entered the uh sandbox. It got the answers somewhere over here.  01:35:34 The Admin: Drag output also came. Then there's another function called again searching document. Maybe just a repeat of what happened. Yeah, it's a double lock event and it said max step reached but it has not run thrice. Right. So there's a bit bit of bug that I would like you to solve. It's a very small bug but moment to solve it you'll realize that um how beautiful the architecture actually is. This is not the most optimized architecture. The prompts are really long as I said is 6,000 characters long. It's going to be very short. Longer the prompt then we have tool descriptions and other thing also coming in. then a query then the past memory then what I did last summer then don't share what I did in last week all that stuff is there and memory is also not there moment we add memory it's going to become even bigger okay so step one of your assignment is explain the architecture in full detail include a chart or a graph handdrawn or using an app then fix that error in the framework which will not allow you to run some of the other queries that are shared in the agent py the assignment basically is to make sure that you fix the and also are able to run all of these functions already there.  01:36:43 The Admin: Then you also need to write 10 heristics that run on a query and the result. Think of removing band words and other things that we discussed, right? We discussed a lot of uh heristics today. Pick at least 10. Index your past historical conversation and provide to your agent. Do this in a very smart way. A lot of score for this if you are able to do this. Basically, if I ask how much Anulan paid to DF blah blah blah twice. Second time, it should not even run. should just come back from the history and say that maybe one call uh LM call where it goes memory goes and say look the last time you said 43.75 and that's the answer right then distant prom conversion txt has 729 words reduce it to less than 300 without breaking the performance say more and less words are we clear so this is really the first time You're going to be looking at the architecture from the point of view that how it is written. What are the small small function that are part of the uh overall architecture?  01:37:43 The Admin: You have you have to make sure that you are thorough for the architecture part. You're going to be writing a prompt uh you're going to see a prompt that actually works but you're going to be dropping it by 50% from 729 to 300 words. You're also going to be writing your own code for heristics to make sure that at least these things are taken care and they are simple. Heristics is actually simple. Are you going to write a Python function that's going to be injected in a loop? Now, how do you inject something in a loop that I have written? By understanding the code that's why this the step that in which you have to actually write the step 1 2 3 4 5 is the only way in which you can solve this assignment. A very interesting one and I hope you really like the assignment and go deeper inside. Moment you are done with this architecture in the next one you're going to see. Okay, another architecture. The final architecture as I said is going to be discussed in the last five session where we're going to be uh building the architecture purely dynamic.  01:38:33 The Admin: We have no clue which agent is going to be called and that's a beautiful part. We're going to ask a question and it's going to decide which agent to call the perception going to be called or not rack will be used complete end toend thought process and it's going to come back with an answer. That's the last agent that we're going to be writing. Take us around four five sessions to write that. That's assignment and now we're open for questions.Nithya Raghav: uh can you please explain the bug once again? I I couldn't catch that. And the second thing is okay but you are showing something on the screen right you told okay got it gotThe Admin: No, you have to find the bug. No, I I No, no. I said fix an error in the framework which would not allow you to run other queries. I ran one of the query and I showed you the answer. I ran this query and it didn't work. That's all I did.  01:39:22 Nithya Raghav: it okay got it yeah and then the uh uh the third point in the assignments that you have listed can you please explain What are you submitting in that the third point uh your GitHub report? So for a new Okay.The Admin: your architectural diagram. This is architecture diagram. Bug fix support. What was the bug in your GitHub uh repo?Nithya Raghav: Okay.The Admin: Read me should have details and full uh three examples of full log. So basically you're proving that it can run for this this and this or any three. This I already showed it's running. So the readme file shows that your heristic file link this heristic file historical conversation shows a JSON or something similar where you're storing your historical conversation in your decision prompt because you need to write it in half the words. Uh total word count in your decision prompt. Here I will read it. Here I'll see how many words you have and a YouTube video where you're showing that things are working.  01:40:20 Nithya Raghav: Okay.The Admin: See something correct.Nithya Raghav: And all this are above the files that you have shared. Now this complete assignment.The Admin: This is all the fi files are here.Nithya Raghav: Okay. Okay. ThankThe Admin: These files are these files. All right. Namas.Nawaz Ali: Ron for the first task like do we need to go in functionality level or let's say from agent uh the control is going to the perception perception is going to memory.The Admin: Yes. Step by step every Yes. Step step by step every function and every file. What is the existence of every single file that is there? How the information is flowing? So it's pure architectural diagram.Nawaz Ali: So we are talking of files but the files will have like the loop will have multiple uh functions again being called right. So do you want us to explain at that level at the function level or is it just based on how will the control flow once we give in the user query how will the control flow from uh one  01:41:25 The Admin: It is the architecture of the program which needs to describe the flow of the information.Nawaz Ali: file.The Admin: If a function used for something that has to be mentioned for example in heristics you have 10 function you will not mention 10 function just say heristics or the loop control something like that shorten it.Nawaz Ali: Okay. All right. I I'll Okay, makes sense.The Admin: So it can be seen in one diagram.Nawaz Ali: Got it. Uh another followup. Uh for the the 10 heristics that we'll be writing on. uh is it something that it has to be related to your code or can we take that file does not exist and we can start working like we can create for that right got it thankThe Admin: No, completely. Yeah, you can do that. Yeah, we discussed on 38 today. If you see the video, it'll be there in some time. Any of those or you can come up with your own. All right. Any other question?satish jasthi: Rohan in general when we are attempting like for a new problem statement as you were uh suggesting there'll be different architectural um uh choices right based on the problem statement so would you suggest something like going over the entire flow of like like you know from user query to all the possibilities like how we do in app design with the Figma thing for UI because that would give us the entire flow and in each flow we  01:43:01 satish jasthi: can even come up with like huristics or like the checks that we need to do or is it is are there better alternatives based on your experience?The Admin: So uh the architect how the architecture is going to be evolving is uh what you said is a solving the generic a specific problem in the agent AI world for that for that what you said is the rightsatish jasthi: Yeah.The Admin: way by the time we're going to be ending our course you're going to see that our assignments will keep on changing so The strategy that you picked in assignment 12 may not work for 13, may not work forsatish jasthi: Okay.The Admin: 14. So we try and come up with a generic architecture which can solve 90% of the problem and can be modified to fine-tune for one particular one.satish jasthi: Okay. Okay. So, it's a generic template which can be fine tuned for a specific use case.The Admin: Correct? That that's where we want to go with this.satish jasthi: Okay. Cool. Thank.The Admin: Like we discussed that for a stock trading, we have a day trader and we have a long trader.  01:43:57 satish jasthi: Yeah. Yeah.The Admin: So can the same architecture work for both? Answer is no. Unless we have provided enough diversity to attack both problem. That's the architecture we want to go. Our architecture can suit both of them.satish jasthi: Makes sense. Yep.The Admin: Okay. Sin summarize it.Sachin Bharadwaj: Yeah. uh so what kind of problems cannot be solved by let's say uh by code only uh like small agents right and then but but if I say summarize right I mean I can al also invoke a llm callThe Admin: Summarize the text. Summarize this page. Then it's not code only.Sachin Bharadwaj: so lm call in a code is not termed as a code agenda but it can use MCP tools right which are which are external APIs Sorry,The Admin: No, it's not code is going inside Python sandbox and answer is coming from Python sandbox. See can I prove that sun rises in west? I can.Sachin Bharadwaj: I I didn't get that wrong.The Admin: Can I prove sun rises in the west?  01:44:54 The Admin: I can. Right.Sachin Bharadwaj: Yeah.The Admin: I I just to find a planet that is rotating. So that's that's the discussion we're having right now. When we saying code agent that means that LLM is not being called.Sachin Bharadwaj: Mhm.The Admin: You're saying no I will call the LM through MCP. Then it's perfectly fine. But then you are basically working on a gray line.Sachin Bharadwaj: No, I'm just asking a bigger question than that. I mean that just is too specific for this use case, right? I'm just saying can every problem be solved as as code as an agent, right? Because I think and at the end software, right?The Admin: Okay. See I'll give you one more example. You will say that I'll call I'll call another LM for that. For example, write a poem on India and Africa together. You're going to say I will write up function and call LLM which can do it. That way then everything can be done through code.  01:45:38 The Admin: But there is some LM which is allowed to speak allowed to not do code or for example draw an image.Sachin Bharadwaj: Mhm. All right.The Admin: uh you can again say from MCP I can call image in and Gemini can draw the image. So but moment you're passing on the problem out of the sandbox it's not a code agent alone we are spec we're talking about can you write a code and do the same problem that that's the code agent can you write equivalent code and solve the problem without internet without going out of that Python code that's a code agent but moment we allow it to go outside we are going back to agent again becomes a agentSachin Bharadwaj: Mhm. Okay. All right. Thanks.Pratesh Kumar Reddy R: Uh when you meant Python sandbox like how do we create that? Is there any uhThe Admin: Yeah, it's it's created already. Should be part of the action. Yeah. Action. Here's a sandbox.Pratesh Kumar Reddy R: Okay.  01:47:01 Pratesh Kumar Reddy R: So, it makes sure that none of the unsafe commands are uh not run or something.The Admin: Correct.Pratesh Kumar Reddy R: Okay. I'll check this. Thank you.The Admin: modules action run Python sandbox. So let's go to modules action run Python sandbox. Here we're defining a class we're calling a dispatcher and dispatcher call to we're calling a tool inside the sandbox. Right as I said that the problem of writing a custom code and solving that is not solved that that is going to come the execution py that file is not here that file will be there s10 where we will allow for the random code to be generated and to be solved and add guard rules there.Pratesh Kumar Reddy R: Okay. So does this sandbox currently take care of suppose RM minus RF and all?The Admin: It it does not but it will automatically not work because shell is not supported.Pratesh Kumar Reddy R: Okay. Okay. Okay.Amlan Routray: Hey Ron, so um so what I understood is like um we have to have a summarized tool in the action or tools uh but that code will be created in the sandbox like that uh like uh we did earlier like every or um Okay.  01:48:30 The Admin: No, no, no, no, no, no, no, no, no, no. Hold on. Right now. Your decision can only write code. Are we clear?Amlan Routray: Mhm. Yes.The Admin: So it cannot summarize. It cannot write a poem.Amlan Routray: Okay. Okay.The Admin: It cannot do anything that requires creativity. It can only write code and code only can call the function that are in the MCP. So it can do rag. It can do internet search and so on and so on. All it can do either can write code or it can write final answer 14.69 cr something like that. that that is its capability right now. This is the limitation of S9. S10 will allow it to either write code or do these things.Amlan Routray: Okay. And we uh uh if in the sessions that we had 6 7 8 and all we had code where we were implementing this sum uh this summarization call or poem call or any of the calls.  01:49:44 The Admin: Correct.Amlan Routray: Now the code has to do it.The Admin: In yeah S8 and earlier our decision could do anything including a function call but function was being run by somebody else.Amlan Routray: Yeah.The Admin: So we had to run a loop catch the function and do something.Amlan Routray: Okay.The Admin: Right now this is this and action or basically function calling are coupled together. So we know that it's only giving a code.Amlan Routray: Right. Okay. And I have a question from previous session.The Admin: Yeah.Amlan Routray: Should we ask now?The Admin: Yeah. Go ahead.Amlan Routray: Okay. So uh so in the last assignment we had to like um I as I went ahead with the design that I I kind of prefer the padm where um uh I didn't use the code that you had that loop and uh context and all and I was able to uh solve in that way but I didn't understand what is the use of loop as in what additional benefit does the core module that you have the loop and context brings in because uh in my code agent py as is the orchestrator is the main one which is doing uh is calling things in uh serally uh but having a loops py I didn't understand that what is the use of it or is it actually this s9 will going to Mhm.  01:50:54 The Admin: as yeah as as when you when you answer the question this particular question you understand why do we need them separately can see it's modularity which problem is solved in which particular file so when I'm sharing the code I have to follow that also but but ideally loop and agent are one the same But agent py has a context of orchestration.Amlan Routray: Okay. Is it uh something is I'm not sure is this agent py is the orchestrator of orchestrators. Uhhuh.The Admin: The loop tools which happen to be related to python code are in loop. py right?Amlan Routray: Okay.The Admin: It's separation of concern. Whenever we write a Python code, we need to look at a separation of concern. For example, I want my loop to have some heristics. I should not be going into the agent. And add heristics there, right?Amlan Routray: Okay.The Admin: Heristics should be coupled directly with the loop because in the loop the information comes in and goes forward.Amlan Routray: H. Okay.The Admin: So that so that's where the separation of concern comes in. That's where architecture takes a particular form.  01:51:57 Amlan Routray: Okay. It's like decoupling as in separating just having the main functionality of those files and those files.The Admin: Yes.Amlan Routray: Exactly. Okay.The Admin: Yes.Amlan Routray: Thank you.The Admin: Believe me, it is much better to have 25 files compared to one single line of one single file where like 2500 lines of code are there.Amlan Routray: Yeah. Okay. Yeah.Venkatesh Babu D B: So Rohan in the point where you said index your past historical conversation we allow use f a ss.The Admin: Not required. We can we can just write a simple function for that. FS is required when the data is too big. So for S9 not required thisVenkatesh Babu D B: Okay.Pratesh Kumar Reddy R: uh Rohan can I uh like suppose I can write some functions here run command and inside that I'm calling subprocess.pop P open and what command to run is coming from LLM based upon my prompt uh and I create a guard rails around it like suppose uh this some of the set of unsafe commands that shouldn't be run is that a correct way to like that is it a correct way to approach any uh yeah suppose I  01:53:25 The Admin: Uh, please repeat.Pratesh Kumar Reddy R: create a function say run command and uh inside that run command I'm no generally uh just a python function say run command and then inside that I'm calling subprocess.pop P open and I'm allowing access to shell in directly.The Admin: You create one one one second. You create a you're talking about my run or the Windows run. Okay. Okay.Pratesh Kumar Reddy R: Uh and which command to run is coming from LLM like suppose I say uh what is my current g branch and then llm decides okay I have to run uh git branch and then get the output.The Admin: Okay.Pratesh Kumar Reddy R: So which command to run is coming from llm based upon my prompt but I'm giving access to my uh shell here in internally uh and I create few guard rails like say should if the command is rm minusThe Admin: Okay, correct.Pratesh Kumar Reddy R: rf for anything don't run uh is that a correct way to approach because that avoids lot lot of tools to be written mcp tools suppose I don't have to write a tool for finding out the g branch because I can allow llm to just come up with that But as soon as I give access to my shell, it's like the sandbox is not there right is that  01:54:28 The Admin: Yes, this is this is the right approach as long as the whole thing is running in a sandbox and they are guarded. No sandbox will not let this these terms also to come in unless you have specifically mentioned that they can come in. So your sandbox has to be very strong. What all modules are allowed? What all terms are allowed? It's a set of histics as well.Pratesh Kumar Reddy R: okay. So uh the only way I can not allow this unsafe commands is by just listing out which these are all unsafe and uh not run it is like heristically I have to do it isThe Admin: Yes. One is heristics. And let's say if I were to go in production, I will actually use an LLM to look at this this command and make sure it's safe.Pratesh Kumar Reddy R: okay lm has to decide again whether it's safe or not Okay.The Admin: Correct.Pratesh Kumar Reddy R: Okay.The Admin: And we we are soon going to go in that direction. Right now we have perception and then we have decision. Right? Soon we are going to see that we have perception, we have decision but we have critic also. And slowly we are going to merge perception inside critic. So our final architecture is going to be critic and actor. Decision is going to become actor and perception going to become critic.Pratesh Kumar Reddy R: Okay. Got it. Got it. Thank you.Venkatesh Babu D B: So Rohan for the huristic file any particular format to be followed or is there a standard format?The Admin: Histics is a set of functions that you're going to be calling on.ext.Venkatesh Babu D B: Okay. So it'll be a Python file.The Admin: It's a Python file. I think it's part of S10 for me.Venkatesh Babu D B: Okay.The Admin: All right guys, I'm still here. If you have any question, but I'm stopping the recording. Please make sure that you take this assignment very seriously.  Transcription ended after 01:56:27This editable transcript was computer generated and might contain errors. People can also change the text after it was created.